{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ba867d-efbb-4265-9cbd-2e66a76bb547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./Ray_finrl/findrl_ray/finenv')\n",
    "from finenv.env_stocktrading import StockTradingEnv\n",
    "from finenv.preprocessors import FeatureEngineer, data_split\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import psutil\n",
    "import ray, time\n",
    "ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total\n",
    "from ray.tune.registry import register_env\n",
    "from gymnasium.wrappers import EnvCompatibility\n",
    "# load the DataFrame from a pickle file\n",
    "#df = pd.read_pickle('dataset/processed.pkl')\n",
    "trade = pd.read_csv('dataset/trade_data.csv')\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89700baa-b683-4a5e-87d0-41c304bde9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INDICATORS = ['macd','boll_ub','boll_lb','rsi_30','cci_30','dx_30','close_30_sma','close_60_sma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a183cc2-659f-4fd9-a986-d08d550dfb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 82, State Space: 821\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39818dc-1cde-47c3-a477-1bf85ded87ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "env_kwargs = {\n",
    "    \"hmax\": 500,\n",
    "    \"initial_amount\": 3000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = None, risk_indicator_col= 'vix', **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facb2fd7-35ff-4f30-bf5d-7e3ebc83f640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def env_creator_trading(env_config):\n",
    "    # env_config is passed as {} and defaults are set here\n",
    "    df = env_config.get('df', trade)  # changed from the training environment\n",
    "    hmax = env_config.get('hmax', 500)\n",
    "    initial_amount = env_config.get('initial_amount', 3000000)\n",
    "    num_stock_shares = env_config.get('num_stock_shares', [0] * stock_dimension)\n",
    "    buy_cost_pct = env_config.get('buy_cost_pct', buy_cost_list)\n",
    "    sell_cost_pct = env_config.get('sell_cost_pct', sell_cost_list)\n",
    "    state_space = env_config.get('state_space', 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension)\n",
    "    stock_dim = env_config.get('stock_dim', stock_dimension)\n",
    "    tech_indicator_list = env_config.get('tech_indicator_list', INDICATORS)\n",
    "    action_space = env_config.get('action_space', stock_dimension)\n",
    "    reward_scaling = env_config.get('reward_scaling', 1e-4)\n",
    "    # specific for trading\n",
    "    #turbulence_threshold = env_config.get('turbulence_threshold', 70)\n",
    "    #risk_indicator_col = env_config.get('risk_indicator_col', 'vix')\n",
    "    return EnvCompatibility(StockTradingEnv(\n",
    "        df=df,\n",
    "        hmax=hmax,\n",
    "        initial_amount=initial_amount,\n",
    "        num_stock_shares=num_stock_shares,\n",
    "        buy_cost_pct=buy_cost_pct,\n",
    "        sell_cost_pct=sell_cost_pct,\n",
    "        state_space=state_space,\n",
    "        stock_dim=stock_dim,\n",
    "        tech_indicator_list=tech_indicator_list,\n",
    "        action_space=action_space,\n",
    "        reward_scaling=reward_scaling,\n",
    "        #turbulence_threshold=turbulence_threshold,\n",
    "        #risk_indicator_col=risk_indicator_col\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df4d8e7-549d-4340-94a8-d7803c908d42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 21:48:36,682\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.agents import ppo\n",
    "ray.shutdown()\n",
    "ray.init(\"auto\")\n",
    "config = ppo.PPOConfig()\n",
    "config = config.environment(env_config={'hmax':500,'initial_amount':300000})\n",
    "config = config.evaluation() \n",
    "config = config.resources(num_gpus=0)\n",
    "config = config.rollouts(num_rollout_workers=0) \n",
    "config = config.framework(framework=\"torch\")\n",
    "config = config.exploration(explore=False)\n",
    "config['explore'] = False\n",
    "config['seed'] = 0\n",
    "config[\"model\"][\"fcnet_hiddens\"] = [256, 128, 128, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0c3f1e-69f1-41fc-ae35-290b40518074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# registering the environment to ray\n",
    "register_env(\"finrl\", env_creator_trading)\n",
    "#trainer = config.build(env=\"finrl\")\n",
    "#trainer = ppo.PPOTrainer(env='finrl', config=config)\n",
    "#trainer = config.build(env='finrl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c625d4-f48e-4089-8a17-40617099945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=13944)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13944)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13937)\u001b[0m 2023-04-03 21:49:13,866\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13937)\u001b[0m 2023-04-03 21:49:13,867\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13937)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=13937)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +53s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +53s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +1m28s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +2m3s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +2m38s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +3m13s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +3m49s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +4m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +4m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +5m34s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +6m9s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +6m44s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +7m19s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +7m54s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +8m29s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +9m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +9m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +10m14s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "#from ray.rllib.algorithms.ppo import PPO\n",
    "cwd_checkpoint = 'model/ppo/checkpoint_000500'\n",
    "#trainer.restore(cwd_checkpoint)\n",
    "#agent = ppo.PPOTrainer(config=config, env='finrl')\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "# Use the Algorithm's `from_checkpoint` utility to get a new algo instance\n",
    "# that has the exact same state as the old one, from which the checkpoint was\n",
    "# created in the first place:\n",
    "trainer = Algorithm.from_checkpoint(cwd_checkpoint)\n",
    "#trainer.restore(cwd_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56b7e8-8e68-49c4-9654-14fdb5fd2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRL_prediction(model, environment):\n",
    "    start = time.time()\n",
    "    \"\"\"make a prediction\"\"\"\n",
    "    state = environment.reset()\n",
    "    for i in range(len(environment.df.index.unique())):\n",
    "        action = model.compute_single_action(state, explore=False)\n",
    "        state, reward, done, _ = environment.step(action)\n",
    "        if i == (len(environment.df.index.unique()) - 1):\n",
    "            account_memory = environment.save_asset_memory()\n",
    "            actions_memory = environment.save_action_memory()\n",
    "        if done:\n",
    "            break\n",
    "    print(f'Test Took:{(time.time()-start)}s')\n",
    "    return account_memory, actions_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6fd91f-f8b3-4ba3-ac53-c49abd24d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value, df_actions = DRL_prediction(model=trainer, environment = e_trade_gym)\n",
    "print(df_account_value.iloc[-1]['account_value'])\n",
    "df_actions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cafa1-4274-41aa-ba46-7b7ade9192f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    df_account_value, df_actions = DRL_prediction(model=trainer, environment = e_trade_gym)\n",
    "    print(df_account_value.iloc[-1]['account_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5a97f-7d46-4f19-b6f1-99c63832c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Trades\n",
    "counts = (df_actions > 0).sum()\n",
    "tdays = int(df_actions.shape[0])\n",
    "print(f'Trades:{counts.sum()}\\nTrade Days:{tdays}\\nTrades Per Day:{counts.sum()/tdays:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6af50-ccdf-44a1-abe9-3e42a01d1b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_actions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58970692-6b80-41e7-8579-1fd0b61eb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./results/\"+\"perf_stats_all\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a56ce5-3e4a-4ff0-a7a9-4a7ac1e9af94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379939db-fe97-47cd-9e4c-90840e21a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Compare to NDX===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^NDX', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ff5b8-c7c6-48db-a84d-0b544f400698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
