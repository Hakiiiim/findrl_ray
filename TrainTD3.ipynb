{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba7f2b6-480a-4462-af82-80e6d588cd8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "import os\n",
    "import finrl\n",
    "from finenv.env_stocktrading import StockTradingEnv\n",
    "from finenv.preprocessors import data_split\n",
    "from finenv.save_model import *\n",
    "import psutil\n",
    "import ray\n",
    "from datetime import datetime\n",
    "ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total\n",
    "from ray.tune.registry import register_env\n",
    "from gymnasium.wrappers import EnvCompatibility\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.algorithms.td3 import TD3Config\n",
    "from ray.rllib.algorithms.ddpg.ddpg import DDPGConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7882d0a-464f-46ed-8be6-e22b4ba58596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 82, State Space: 821\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>AAL</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>4.940000</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.496876</td>\n",
       "      <td>9837300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.496876</td>\n",
       "      <td>4.496876</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7.622500</td>\n",
       "      <td>7.660714</td>\n",
       "      <td>7.585000</td>\n",
       "      <td>6.505280</td>\n",
       "      <td>493729600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.505280</td>\n",
       "      <td>6.505280</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>36.650002</td>\n",
       "      <td>37.299999</td>\n",
       "      <td>36.650002</td>\n",
       "      <td>37.090000</td>\n",
       "      <td>4710200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>37.090000</td>\n",
       "      <td>37.090000</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>ADI</td>\n",
       "      <td>31.790001</td>\n",
       "      <td>32.189999</td>\n",
       "      <td>31.610001</td>\n",
       "      <td>22.960766</td>\n",
       "      <td>2102700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.960766</td>\n",
       "      <td>22.960766</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>ADP</td>\n",
       "      <td>38.226513</td>\n",
       "      <td>38.226513</td>\n",
       "      <td>37.489025</td>\n",
       "      <td>27.336391</td>\n",
       "      <td>3930120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.336391</td>\n",
       "      <td>27.336391</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>ADSK</td>\n",
       "      <td>25.610001</td>\n",
       "      <td>25.830000</td>\n",
       "      <td>25.610001</td>\n",
       "      <td>25.670000</td>\n",
       "      <td>2228600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.670000</td>\n",
       "      <td>25.670000</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>ALGN</td>\n",
       "      <td>18.049999</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>18.049999</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>374200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>AMAT</td>\n",
       "      <td>14.050000</td>\n",
       "      <td>14.570000</td>\n",
       "      <td>14.030000</td>\n",
       "      <td>11.302063</td>\n",
       "      <td>18615100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.302063</td>\n",
       "      <td>11.302063</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>AMD</td>\n",
       "      <td>9.790000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.680000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>18748700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>56.630001</td>\n",
       "      <td>57.869999</td>\n",
       "      <td>56.560001</td>\n",
       "      <td>42.888947</td>\n",
       "      <td>5277400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.471366</td>\n",
       "      <td>4.031468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.888947</td>\n",
       "      <td>42.888947</td>\n",
       "      <td>20.040001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   tic       open       high        low      close       volume  \\\n",
       "                                                                               \n",
       "0  2010-01-04   AAL   4.840000   4.940000   4.660000   4.496876    9837300.0   \n",
       "0  2010-01-04  AAPL   7.622500   7.660714   7.585000   6.505280  493729600.0   \n",
       "0  2010-01-04  ADBE  36.650002  37.299999  36.650002  37.090000    4710200.0   \n",
       "0  2010-01-04   ADI  31.790001  32.189999  31.610001  22.960766    2102700.0   \n",
       "0  2010-01-04   ADP  38.226513  38.226513  37.489025  27.336391    3930120.0   \n",
       "0  2010-01-04  ADSK  25.610001  25.830000  25.610001  25.670000    2228600.0   \n",
       "0  2010-01-04  ALGN  18.049999  18.500000  18.049999  18.500000     374200.0   \n",
       "0  2010-01-04  AMAT  14.050000  14.570000  14.030000  11.302063   18615100.0   \n",
       "0  2010-01-04   AMD   9.790000   9.900000   9.680000   9.700000   18748700.0   \n",
       "0  2010-01-04  AMGN  56.630001  57.869999  56.560001  42.888947    5277400.0   \n",
       "\n",
       "   day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  close_30_sma  \\\n",
       "                                                                           \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0      4.496876   \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0      6.505280   \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0     37.090000   \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0     22.960766   \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0     27.336391   \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0     25.670000   \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0     18.500000   \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0     11.302063   \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0      9.700000   \n",
       "0  0.0   0.0  5.471366  4.031468   100.0  66.666667  100.0     42.888947   \n",
       "\n",
       "   close_60_sma        vix  turbulence  \n",
       "                                        \n",
       "0      4.496876  20.040001         0.0  \n",
       "0      6.505280  20.040001         0.0  \n",
       "0     37.090000  20.040001         0.0  \n",
       "0     22.960766  20.040001         0.0  \n",
       "0     27.336391  20.040001         0.0  \n",
       "0     25.670000  20.040001         0.0  \n",
       "0     18.500000  20.040001         0.0  \n",
       "0     11.302063  20.040001         0.0  \n",
       "0      9.700000  20.040001         0.0  \n",
       "0     42.888947  20.040001         0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = True\n",
    "if csv:\n",
    "    train = pd.read_csv('dataset/train_data.csv')\n",
    "    train = train.set_index(train.columns[0])\n",
    "    #train.reset_index(drop=True, inplace=True)\n",
    "    train.index.names = ['']\n",
    "    INDICATORS = ['macd','boll_ub','boll_lb','rsi_30','cci_30','dx_30','close_30_sma','close_60_sma']\n",
    "\n",
    "else: \n",
    "    train = pd.read_csv('dataset/idxetf_train.csv')\n",
    "    train = train.set_index(train.columns[0])\n",
    "    train.index.names = ['']\n",
    "    INDICATORS = ['macd','rsi','cci','adx']\n",
    "    \n",
    "stock_dimension = len(train.tic.unique())\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension    \n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "train.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb6781a9-96f3-4a91-8819-960f699e2438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def env_creator(env_config):\n",
    "    # env_config is passed as {} and defaults are set here\n",
    "    df = env_config.get('df', train)\n",
    "    hmax = env_config.get('hmax', 200)\n",
    "    initial_amount = env_config.get('initial_amount', 1000000)\n",
    "    num_stock_shares = env_config.get('num_stock_shares', [0] * stock_dimension)\n",
    "    buy_cost_pct = env_config.get('buy_cost_pct', buy_cost_list)\n",
    "    sell_cost_pct = env_config.get('sell_cost_pct', sell_cost_list)\n",
    "    state_space = env_config.get('state_space', 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension)\n",
    "    stock_dim = env_config.get('stock_dim', stock_dimension)\n",
    "    tech_indicator_list = env_config.get('tech_indicator_list', INDICATORS)\n",
    "    action_space = env_config.get('action_space', stock_dimension)\n",
    "    reward_scaling = env_config.get('reward_scaling', 1e-2)\n",
    "\n",
    "    return EnvCompatibility(StockTradingEnv(\n",
    "        df=df,\n",
    "        hmax=hmax,\n",
    "        initial_amount=initial_amount,\n",
    "        num_stock_shares=num_stock_shares,\n",
    "        buy_cost_pct=buy_cost_pct,\n",
    "        sell_cost_pct=sell_cost_pct,\n",
    "        state_space=state_space,\n",
    "        stock_dim=stock_dim,\n",
    "        tech_indicator_list=tech_indicator_list,\n",
    "        action_space=action_space,\n",
    "        reward_scaling=reward_scaling\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3d58e55-a77f-4d4a-843b-e4291e9fd2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray is being initialized\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "register_env(\"finrl\", env_creator)\n",
    "#ray.init(num_cpus=122,dashboard_port=8080)\n",
    "print(f\"ray is being initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116a4f64-e0e5-4204-bb9c-0f6c8d2fa2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 20:49:28,604\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3856)\u001b[0m 2023-04-09 20:49:37,566\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3856)\u001b[0m 2023-04-09 20:49:37,566\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3856)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3856)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3869)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3869)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3896)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3896)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3883)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3883)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3910)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3910)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3939)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3939)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3924)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3924)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3997)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3997)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3953)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=3953)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4026)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=4026)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "2023-04-09 20:49:38,681\tINFO trainable.py:172 -- Trainable.setup took 13.196 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "#config = DDPGConfig().training(lr=0.01).resources(num_gpus=1).framework(framework=\"torch\").rollouts(num_rollout_workers=10)\n",
    "config = TD3Config().training(lr=0.01).resources(num_gpus=1).framework(framework=\"torch\").rollouts(num_rollout_workers=10)\n",
    "config[\"model\"][\"fcnet_hiddens\"] = [1024,1024]\n",
    "config['train_batch_size'] = 1024\n",
    "#print(config.to_dict())  \n",
    "# Build a Trainer object from the config and run one training iteration.\n",
    "trainer = config.build(env=\"finrl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67da4c9a-dcef-4c02-a17a-31a5e1b4c0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd17e91c5724691a37cd6cd8fb379a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Episodes:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 20:49:40,067\tWARNING replay_buffer.py:61 -- Estimated max memory usage for replay buffer is 6.946 GB (1000000.0 batches of size 1, 6946 bytes each), available system memory is 25.214959616 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rwd:nan\n",
      "Mean Rwd:49705.832041753965\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m ep \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m total_episodes:\n\u001b[0;32m---> 11\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m     ep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m     bar\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/tune/trainable/trainable.py:365\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 365\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    367\u001b[0m     skipped \u001b[38;5;241m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py:782\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m     (\n\u001b[1;32m    775\u001b[0m         results,\n\u001b[1;32m    776\u001b[0m         train_iter_ctx,\n\u001b[1;32m    777\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 782\u001b[0m     results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mevaluation_parallel_to_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py:2713\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2711\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[1;32m   2712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_disable_execution_plan_api:\n\u001b[0;32m-> 2713\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2714\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2715\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/algorithms/simple_q/simple_q.py:348\u001b[0m, in \u001b[0;36mSimpleQ.training_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m     train_results \u001b[38;5;241m=\u001b[39m train_one_step(\u001b[38;5;28mself\u001b[39m, train_batch)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 348\u001b[0m     train_results \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_gpu_train_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# Update replay buffer priorities.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m update_priorities_in_replay_buffer(\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_replay_buffer,\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    354\u001b[0m     train_batch,\n\u001b[1;32m    355\u001b[0m     train_results,\n\u001b[1;32m    356\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/execution/train_ops.py:163\u001b[0m, in \u001b[0;36mmulti_gpu_train_one_step\u001b[0;34m(algorithm, train_batch)\u001b[0m\n\u001b[1;32m    158\u001b[0m         permutation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(num_batches)\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;66;03m# Learn on the pre-loaded data in the buffer.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;66;03m# Note: For minibatch SGD, the data is an offset into\u001b[39;00m\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;66;03m# the pre-loaded entire train batch.\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m             results \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_on_loaded_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mper_device_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m             learner_info_builder\u001b[38;5;241m.\u001b[39madd_learn_on_batch_results(results, policy_id)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Tower reduce and finalize results.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py:771\u001b[0m, in \u001b[0;36mTorchPolicyV2.learn_on_loaded_batch\u001b[0;34m(self, offset, buffer_index)\u001b[0m\n\u001b[1;32m    768\u001b[0m     batch_fetches[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtower_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m: custom_metrics}\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# Do the (maybe parallelized) gradient calculation step.\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m tower_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_multi_gpu_parallel_grad_calc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# Mean-reduce gradients over GPU-towers (do this on CPU: self.device).\u001b[39;00m\n\u001b[1;32m    774\u001b[0m all_grads \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py:1255\u001b[0m, in \u001b[0;36mTorchPolicyV2._multi_gpu_parallel_grad_calc\u001b[0;34m(self, sample_batches)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fake_gpus\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m shard_idx, (model, sample_batch, device) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_gpu_towers, sample_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices)\n\u001b[1;32m   1254\u001b[0m     ):\n\u001b[0;32m-> 1255\u001b[0m         \u001b[43m_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;66;03m# Raise errors right away for better debugging.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m         last_result \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py:1199\u001b[0m, in \u001b[0;36mTorchPolicyV2._multi_gpu_parallel_grad_calc.<locals>._worker\u001b[0;34m(shard_idx, model, sample_batch, device)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;66;03m# Recompute gradients of loss over all variables.\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m loss_out[opt_idx]\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1198\u001b[0m grad_info\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m-> 1199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_grad_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mopt_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1200\u001b[0m )\n\u001b[1;32m   1202\u001b[0m grads \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;66;03m# Note that return values are just references;\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;66;03m# Calling zero_grad would modify the values.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/algorithms/ddpg/ddpg_torch_policy.py:336\u001b[0m, in \u001b[0;36mDDPGTorchPolicy.extra_grad_process\u001b[0;34m(self, optimizer, loss)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@override\u001b[39m(TorchPolicyV2)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextra_grad_process\u001b[39m(\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m, optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer, loss: TensorType\n\u001b[1;32m    334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, TensorType]:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# Clip grads if configured.\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_grad_clipping\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/utils/torch_utils.py:67\u001b[0m, in \u001b[0;36mapply_grad_clipping\u001b[0;34m(policy, optimizer, loss)\u001b[0m\n\u001b[1;32m     64\u001b[0m     global_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(params, clip_value)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(global_norm, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 67\u001b[0m         global_norm \u001b[38;5;241m=\u001b[39m \u001b[43mglobal_norm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     69\u001b[0m     grad_gnorm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(global_norm, clip_value)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "# Train away -------------------------------------------------------------\n",
    "total_episodes = 500\n",
    "agent_name = 'td3'\n",
    "ep = 0\n",
    "results = []\n",
    "bar = tqdm(total=total_episodes, desc=\"Episodes\")\n",
    "date = datetime.now().strftime('%y%m%d')\n",
    "\n",
    "while ep <= total_episodes:\n",
    "    results.append(trainer.train())\n",
    "    ep += 1\n",
    "    bar.update(n=1)\n",
    "    rwd = results[-1]['episode_reward_mean']\n",
    "    if ep % 20 == 0:\n",
    "        print(f'Mean Rwd:{rwd}')\n",
    "    if ep % 100 == 0:\n",
    "        #cwd_checkpoint = \"results/checkpoints/\" +  + '_' + str(ep)\n",
    "        cwd_checkpoint = f\"model/{agent_name}_{date}\"\n",
    "        trainer.save(cwd_checkpoint)\n",
    "        print(f\"Checkpoint{ep} saved in directory {cwd_checkpoint}\")\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b82920-0746-430c-8c59-5c3467ebd07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save latest ckpt point\n",
    "cwd_checkpoint = f\"model/org_{agent_name}_{date}_{ep}\"\n",
    "trainer.save(cwd_checkpoint)\n",
    "#Extract model weights \n",
    "model_weights = trainer.get_policy().get_weights()\n",
    "print('passed model weights')\n",
    "config2 = TD3Config()\n",
    "print('config created')\n",
    "config2 = config2.environment(env_config={'hmax':500,'initial_amount':1000000})  \n",
    "config2 = config2.rollouts(num_rollout_workers=0) \n",
    "config2 = config2.framework(framework=\"torch\")\n",
    "config2[\"model\"][\"fcnet_hiddens\"] = [256, 256, 256]\n",
    "trainer2 = config2.build(env=\"finrl\") \n",
    "trainer2.get_policy().set_weights(model_weights)\n",
    "print('New Weights loaded. ')\n",
    "ckpt2 = f\"{cwd_checkpoint}_wt\"\n",
    "trainer2.save(ckpt2)\n",
    "zipped_filename = f'ckpt_wt{date}_{ep}.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59824806-2a79-4959-b9a1-4a8074c12015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zipped = zipfilem(ckpt2,zipped_filename)\n",
    "st = sendfile('ckpt_wt230408_53.zip')\n",
    "print(f'file: {zipped} ; {st}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ff5af-5ffb-4fc4-bb64-51eb63e1933f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
