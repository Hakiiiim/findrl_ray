{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ba867d-efbb-4265-9cbd-2e66a76bb547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./Ray_finrl/findrl_ray/finenv')\n",
    "from finenv.env_stocktrading import StockTradingEnv\n",
    "from finenv.preprocessors import FeatureEngineer, data_split\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import psutil\n",
    "import ray, time\n",
    "ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total\n",
    "from ray.tune.registry import register_env\n",
    "from gymnasium.wrappers import EnvCompatibility\n",
    "# load the DataFrame from a pickle file\n",
    "#df = pd.read_pickle('dataset/processed.pkl')\n",
    "trade = pd.read_csv('dataset/trade_data.csv')\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89700baa-b683-4a5e-87d0-41c304bde9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INDICATORS = ['macd','boll_ub','boll_lb','rsi_30','cci_30','dx_30','close_30_sma','close_60_sma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a183cc2-659f-4fd9-a986-d08d550dfb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 82, State Space: 821\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39818dc-1cde-47c3-a477-1bf85ded87ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "env_kwargs = {\n",
    "    \"hmax\": 500,\n",
    "    \"initial_amount\": 3000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = None, risk_indicator_col= 'vix', **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facb2fd7-35ff-4f30-bf5d-7e3ebc83f640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def env_creator_trading(env_config):\n",
    "    # env_config is passed as {} and defaults are set here\n",
    "    df = env_config.get('df', trade)  # changed from the training environment\n",
    "    hmax = env_config.get('hmax', 500)\n",
    "    initial_amount = env_config.get('initial_amount', 3000000)\n",
    "    num_stock_shares = env_config.get('num_stock_shares', [0] * stock_dimension)\n",
    "    buy_cost_pct = env_config.get('buy_cost_pct', buy_cost_list)\n",
    "    sell_cost_pct = env_config.get('sell_cost_pct', sell_cost_list)\n",
    "    state_space = env_config.get('state_space', 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension)\n",
    "    stock_dim = env_config.get('stock_dim', stock_dimension)\n",
    "    tech_indicator_list = env_config.get('tech_indicator_list', INDICATORS)\n",
    "    action_space = env_config.get('action_space', stock_dimension)\n",
    "    reward_scaling = env_config.get('reward_scaling', 1e-4)\n",
    "    # specific for trading\n",
    "    #turbulence_threshold = env_config.get('turbulence_threshold', 70)\n",
    "    #risk_indicator_col = env_config.get('risk_indicator_col', 'vix')\n",
    "    return EnvCompatibility(StockTradingEnv(\n",
    "        df=df,\n",
    "        hmax=hmax,\n",
    "        initial_amount=initial_amount,\n",
    "        num_stock_shares=num_stock_shares,\n",
    "        buy_cost_pct=buy_cost_pct,\n",
    "        sell_cost_pct=sell_cost_pct,\n",
    "        state_space=state_space,\n",
    "        stock_dim=stock_dim,\n",
    "        tech_indicator_list=tech_indicator_list,\n",
    "        action_space=action_space,\n",
    "        reward_scaling=reward_scaling,\n",
    "        #turbulence_threshold=turbulence_threshold,\n",
    "        #risk_indicator_col=risk_indicator_col\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df4d8e7-549d-4340-94a8-d7803c908d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.rllib.agents import ppo\n",
    "ray.shutdown()\n",
    "config = ppo.PPOConfig()\n",
    "config = config.environment(env_config={'hmax':500,'initial_amount':300000})\n",
    "config = config.training(gamma=0.9, lr=0.001, kl_coeff=0.3)  \n",
    "config = config.resources(num_gpus=0)\n",
    "config = config.rollouts(num_rollout_workers=0) \n",
    "config = config.framework(framework=\"torch\")\n",
    "config = config.exploration(explore=False)\n",
    "config['explore'] = False\n",
    "config['seed'] = 0\n",
    "config[\"model\"][\"fcnet_hiddens\"] = [1024, 256, 128,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0c3f1e-69f1-41fc-ae35-290b40518074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# registering the environment to ray\n",
    "register_env(\"finrl\", env_creator_trading)\n",
    "#trainer = config.build(env=\"finrl\")\n",
    "#trainer = ppo.PPOTrainer(env='finrl', config=config)\n",
    "#trainer = config.build(env=\"finrl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c625d4-f48e-4089-8a17-40617099945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 22:41:17,710\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18382)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18382)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18396)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18396)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18375)\u001b[0m 2023-04-02 22:41:26,871\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18375)\u001b[0m 2023-04-02 22:41:26,871\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18375)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18375)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18404)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18404)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18420)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18420)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18389)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18389)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18412)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18412)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18429)\u001b[0m /home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18429)\u001b[0m   logger.warn(\"Casting input x to numpy array.\")\n",
      "2023-04-02 22:41:30,485\tINFO trainable.py:172 -- Trainable.setup took 19.446 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-04-02 22:41:30,509\tWARNING policy.py:1016 -- `observation_space` in given policy state (Box(-inf, inf, (801,), float32)) does not match this Policy's observation space (Box(-inf, inf, (821,), float32)).\n",
      "2023-04-02 22:41:30,511\tWARNING policy.py:1025 -- `action_space` in given policy state (Box(-1.0, 1.0, (80,), float32)) does not match this Policy's action space (Box(-1.0, 1.0, (82,), float32)).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FullyConnectedNetwork:\n\tsize mismatch for _logits._model.0.weight: copying a param with shape torch.Size([160, 16]) from checkpoint, the shape in current model is torch.Size([164, 16]).\n\tsize mismatch for _logits._model.0.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([164]).\n\tsize mismatch for _hidden_layers.0._model.0.weight: copying a param with shape torch.Size([1024, 801]) from checkpoint, the shape in current model is torch.Size([1024, 821]).\n\tsize mismatch for _value_branch_separate.0._model.0.weight: copying a param with shape torch.Size([1024, 801]) from checkpoint, the shape in current model is torch.Size([1024, 821]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Algorithm\n\u001b[1;32m      3\u001b[0m cwd_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/checkpoint_000025\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mAlgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcwd_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py:281\u001b[0m, in \u001b[0;36mAlgorithm.from_checkpoint\u001b[0;34m(checkpoint, policy_ids, policy_mapping_fn, policies_to_train)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`checkpoint_info[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_version\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]` in `Algorithm.from_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()` must be 1.0 or later! You are using a checkpoint with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_version\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m     )\n\u001b[1;32m    274\u001b[0m state \u001b[38;5;241m=\u001b[39m Algorithm\u001b[38;5;241m.\u001b[39m_checkpoint_info_to_algorithm_state(\n\u001b[1;32m    275\u001b[0m     checkpoint_info\u001b[38;5;241m=\u001b[39mcheckpoint_info,\n\u001b[1;32m    276\u001b[0m     policy_ids\u001b[38;5;241m=\u001b[39mpolicy_ids,\n\u001b[1;32m    277\u001b[0m     policy_mapping_fn\u001b[38;5;241m=\u001b[39mpolicy_mapping_fn,\n\u001b[1;32m    278\u001b[0m     policies_to_train\u001b[38;5;241m=\u001b[39mpolicies_to_train,\n\u001b[1;32m    279\u001b[0m )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAlgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py:311\u001b[0m, in \u001b[0;36mAlgorithm.from_state\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    309\u001b[0m new_algo \u001b[38;5;241m=\u001b[39m algorithm_class(config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Set the new algo's state.\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m \u001b[43mnew_algo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# Return the new algo.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_algo\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py:2502\u001b[0m, in \u001b[0;36mAlgorithm.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;66;03m# TODO (sven): Validate that our config and the config in state are compatible.\u001b[39;00m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;66;03m#  For example, the model architectures may differ.\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;66;03m#  Also, what should the behavior be if e.g. some training parameter\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;66;03m#  (e.g. lr) changed?\u001b[39;00m\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[0;32m-> 2502\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2503\u001b[0m     remote_state \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   2504\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mforeach_worker(\n\u001b[1;32m   2505\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m w: w\u001b[38;5;241m.\u001b[39mset_state(ray\u001b[38;5;241m.\u001b[39mget(remote_state)),\n\u001b[1;32m   2506\u001b[0m         local_worker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2507\u001b[0m         healthy_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2508\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py:1697\u001b[0m, in \u001b[0;36mRolloutWorker.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1689\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_policy(\n\u001b[1;32m   1690\u001b[0m                 policy_id\u001b[38;5;241m=\u001b[39mpid,\n\u001b[1;32m   1691\u001b[0m                 policy_cls\u001b[38;5;241m=\u001b[39mpolicy_spec\u001b[38;5;241m.\u001b[39mpolicy_class,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1694\u001b[0m                 config\u001b[38;5;241m=\u001b[39mpolicy_spec\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m   1695\u001b[0m             )\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_map:\n\u001b[0;32m-> 1697\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;66;03m# Also restore mapping fn and which policies to train.\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_mapping_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/policy/torch_mixins.py:108\u001b[0m, in \u001b[0;36mKLCoeffMixin.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_coeff \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_kl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Call super's set_state with rest of the state dict.\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py:965\u001b[0m, in \u001b[0;36mTorchPolicyV2.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_timestep \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_timestep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# Then the Policy's (NN) weights and connectors.\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/policy/policy.py:1035\u001b[0m, in \u001b[0;36mPolicy.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m policy_spec\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# Override NN weights.\u001b[39;00m\n\u001b[0;32m-> 1035\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_connectors(state)\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py:908\u001b[0m, in \u001b[0;36mTorchPolicyV2.set_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;129m@override\u001b[39m(Policy)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;129m@DeveloperAPI\u001b[39m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights: ModelWeights) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    907\u001b[0m     weights \u001b[38;5;241m=\u001b[39m convert_to_torch_tensor(weights, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 908\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FullyConnectedNetwork:\n\tsize mismatch for _logits._model.0.weight: copying a param with shape torch.Size([160, 16]) from checkpoint, the shape in current model is torch.Size([164, 16]).\n\tsize mismatch for _logits._model.0.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([164]).\n\tsize mismatch for _hidden_layers.0._model.0.weight: copying a param with shape torch.Size([1024, 801]) from checkpoint, the shape in current model is torch.Size([1024, 821]).\n\tsize mismatch for _value_branch_separate.0._model.0.weight: copying a param with shape torch.Size([1024, 801]) from checkpoint, the shape in current model is torch.Size([1024, 821])."
     ]
    }
   ],
   "source": [
    "#load model\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "cwd_checkpoint = 'model/checkpoint_000025'\n",
    "trainer = Algorithm.from_checkpoint(cwd_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56b7e8-8e68-49c4-9654-14fdb5fd2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DRL_prediction(model, environment):\n",
    "    start = time.time()\n",
    "    \"\"\"make a prediction\"\"\"\n",
    "    state = environment.reset()\n",
    "    for i in range(len(environment.df.index.unique())):\n",
    "        action = model.compute_single_action(state, explore=False)\n",
    "        state, reward, done, _ = environment.step(action)\n",
    "        if i == (len(environment.df.index.unique()) - 1):\n",
    "            account_memory = environment.save_asset_memory()\n",
    "            actions_memory = environment.save_action_memory()\n",
    "        if done:\n",
    "            break\n",
    "    print(f'Test Took:{(time.time()-start)}s')\n",
    "    return account_memory, actions_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6fd91f-f8b3-4ba3-ac53-c49abd24d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value, df_actions = DRL_prediction(model=trainer, environment = e_trade_gym)\n",
    "print(df_account_value.iloc[-1]['account_value'])\n",
    "df_actions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cafa1-4274-41aa-ba46-7b7ade9192f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    df_account_value, df_actions = DRL_prediction(model=trainer, environment = e_trade_gym)\n",
    "    print(df_account_value.iloc[-1]['account_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5a97f-7d46-4f19-b6f1-99c63832c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Trades\n",
    "counts = (df_actions > 0).sum()\n",
    "tdays = int(df_actions.shape[0])\n",
    "print(f'Trades:{counts.sum()}\\nTrade Days:{tdays}\\nTrades Per Day:{counts.sum()/tdays:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6af50-ccdf-44a1-abe9-3e42a01d1b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_actions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58970692-6b80-41e7-8579-1fd0b61eb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./results/\"+\"perf_stats_all\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a56ce5-3e4a-4ff0-a7a9-4a7ac1e9af94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379939db-fe97-47cd-9e4c-90840e21a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Compare to NDX===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^NDX', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ff5b8-c7c6-48db-a84d-0b544f400698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
