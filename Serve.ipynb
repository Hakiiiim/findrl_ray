{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ba867d-efbb-4265-9cbd-2e66a76bb547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./Ray_finrl/findrl_ray/finenv')\n",
    "from finenv.env_stocktrading import StockTradingEnv\n",
    "from finenv.preprocessors import FeatureEngineer, data_split\n",
    "import pandas as pd\n",
    "import pickle \n",
    "trade = pd.read_csv('dataset/trade_data.csv')\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89700baa-b683-4a5e-87d0-41c304bde9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INDICATORS = ['macd','boll_ub','boll_lb','rsi_30','cci_30','dx_30','close_30_sma','close_60_sma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368e7f69-1f20-4f95-b3cc-49c55c2bc663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import ray\n",
    "ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total\n",
    "from ray.tune.registry import register_env\n",
    "from gymnasium.wrappers import EnvCompatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a183cc2-659f-4fd9-a986-d08d550dfb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facb2fd7-35ff-4f30-bf5d-7e3ebc83f640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def env_creator_trading(env_config):\n",
    "    # env_config is passed as {} and defaults are set here\n",
    "    df = env_config.get('df', trade)  # changed from the training environment\n",
    "    hmax = env_config.get('hmax', 100)\n",
    "    initial_amount = env_config.get('initial_amount', 1000000)\n",
    "    num_stock_shares = env_config.get('num_stock_shares', [0] * stock_dimension)\n",
    "    buy_cost_pct = env_config.get('buy_cost_pct', buy_cost_list)\n",
    "    sell_cost_pct = env_config.get('sell_cost_pct', sell_cost_list)\n",
    "    state_space = env_config.get('state_space', 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension)\n",
    "    stock_dim = env_config.get('stock_dim', stock_dimension)\n",
    "    tech_indicator_list = env_config.get('tech_indicator_list', INDICATORS)\n",
    "    action_space = env_config.get('action_space', stock_dimension)\n",
    "    reward_scaling = env_config.get('reward_scaling', 1e-4)\n",
    "    # specific for trading\n",
    "    return EnvCompatibility(StockTradingEnv(\n",
    "        df=df,\n",
    "        hmax=hmax,\n",
    "        initial_amount=initial_amount,\n",
    "        num_stock_shares=num_stock_shares,\n",
    "        buy_cost_pct=buy_cost_pct,\n",
    "        sell_cost_pct=sell_cost_pct,\n",
    "        state_space=state_space,\n",
    "        stock_dim=stock_dim,\n",
    "        tech_indicator_list=tech_indicator_list,\n",
    "        action_space=action_space,\n",
    "        reward_scaling=reward_scaling,\n",
    "\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5d0511-1889-4928-a324-607b91fadc49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.rllib.agents import ppo\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7df4d8e7-549d-4340-94a8-d7803c908d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = ppo.PPOConfig()\n",
    "config = config.training()\n",
    "config = config.environment(env_config={'hmax':100, 'initial_amount':1000000})\n",
    "config = config.framework(framework=\"torch\")\n",
    "config = config.rollouts(num_rollout_workers=0)\n",
    "config = config.exploration(explore=False)\n",
    "\n",
    "#config[\"model\"][\"fcnet_hiddens\"] = [1024, 256, 128, 32]\n",
    "config['seed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0c3f1e-69f1-41fc-ae35-290b40518074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 17:59:28,472\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "2023-04-03 17:59:30,393\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
      "2023-04-03 17:59:30,394\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "/home/ga_aiot/anaconda3/envs/finrl/lib/python3.8/site-packages/gymnasium/spaces/box.py:227: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "  logger.warn(\"Casting input x to numpy array.\")\n",
      "2023-04-03 17:59:33,519\tINFO trainable.py:172 -- Trainable.setup took 10.718 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "# registering the environment to ray\n",
    "register_env(\"finrl_trading\", env_creator_trading)\n",
    "trainer = config.build(env=\"finrl_trading\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c625d4-f48e-4089-8a17-40617099945e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Checkpoint directory not found for model/checkpoint_000501",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load saved agent\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cwd_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/checkpoint_000501\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcwd_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/tune/trainable/trainable.py:758\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[0;34m(self, checkpoint_path, checkpoint_node_ip, fallback_to_latest)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# Else, raise\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not recover from checkpoint as it does not exist on local \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk and was not available on cloud storage or another Ray node. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot checkpoint path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and IP \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_node_ip\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m     )\n\u001b[0;32m--> 758\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[43mTrainableUtil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_checkpoint_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m metadata \u001b[38;5;241m=\u001b[39m TrainableUtil\u001b[38;5;241m.\u001b[39mload_metadata(checkpoint_dir)\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_as_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;66;03m# If data was saved as a dict (e.g. from a class trainable),\u001b[39;00m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# also pass the dict to `load_checkpoint()`.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/finrl/lib/python3.8/site-packages/ray/tune/trainable/util.py:84\u001b[0m, in \u001b[0;36mTrainableUtil.find_checkpoint_dir\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m     82\u001b[0m     checkpoint_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(checkpoint_dir)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint directory not found for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(checkpoint_path)\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(checkpoint_dir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Checkpoint directory not found for model/checkpoint_000501"
     ]
    }
   ],
   "source": [
    "# load saved agent\n",
    "cwd_checkpoint = 'model/checkpoint_000501'\n",
    "trainer.restore(cwd_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d353b6-738c-40af-b231-7ae17a9c9be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = None, risk_indicator_col= 'vix', **env_kwargs)\n",
    "#e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae3fe6-c45d-47c1-bea4-77cda71ad842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DRL_prediction(model, environment):\n",
    "    \"\"\"make a prediction\"\"\"\n",
    "    state = environment.reset()\n",
    "    # Iterate through given df dates\n",
    "    for i in range(len(environment.df.index.unique())):\n",
    "        action = model.compute_single_action(state)\n",
    "        state, reward, done, _ = environment.step(action)\n",
    "        if i == (len(environment.df.index.unique()) - 2):\n",
    "            account_memory = environment.save_asset_memory()\n",
    "            actions_memory = environment.save_action_memory()\n",
    "        if done:\n",
    "            break\n",
    "    return account_memory, actions_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a1428-35bc-4aba-a8c6-cca1a141edee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_account_value, df_actions = DRL_prediction(model=trainer, environment = e_trade_gym)\n",
    "df_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc144a-e53f-46b5-8680-8e3fe6cc7e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = df_actions.reset_index().to_dict(orient='records')\n",
    "json_str = json.dumps(data)\n",
    "j = json.loads(json_str)\n",
    "# Returns the list for trading with Json. \n",
    "j[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520a24d-9aec-46ab-a30f-0a24625e8360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
